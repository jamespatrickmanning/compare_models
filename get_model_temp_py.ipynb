{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_model_temp.py",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamespatrickmanning/compare_models/blob/master/get_model_temp_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptSRI1-ifpKs",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title zlconversions\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Sep 14 15:08:40 2018\n",
        "update in MARCH 6 add a function find_nd(find the index of nearest distance)\n",
        "@author: leizhao\n",
        "\n",
        "directory list in the end\n",
        "\n",
        "\"\"\"\n",
        "#from __future__ import unicode_literals\n",
        "#import platform\n",
        "#import warnings\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import pytz\n",
        "import datetime\n",
        "import os,shutil\n",
        "import numpy as np\n",
        "import math\n",
        "import difflib\n",
        "import time\n",
        "import requests\n",
        "\n",
        "def angle_conversion(a):\n",
        "    a = np.array(a)\n",
        "    return a/180*np.pi\n",
        "    \n",
        "def copyfile(srcfile,dstfile):\n",
        "    \"\"\"copy file from one folder to another folder\"\"\"\n",
        "    if not os.path.isfile(srcfile):\n",
        "        print (\"%s not exist!\"%(srcfile))\n",
        "    else:\n",
        "        fpath,fname=os.path.split(dstfile) \n",
        "        if not os.path.exists(fpath):\n",
        "            os.makedirs(fpath)\n",
        "        shutil.copyfile(srcfile,dstfile)    \n",
        "   \n",
        "def dist(lat1=0,lon1=0,lat2=0,lon2=0):\n",
        "    \"\"\"caculate the distance of two points, return miles\n",
        "    the format of lat and  lon is 00.00 (dd not dm)\"\"\"\n",
        "    conversion_factor = 0.62137119\n",
        "    R = 6371.004\n",
        "    lon1, lat1 = angle_conversion(lon1), angle_conversion(lat1)\n",
        "    lon2, lat2 = angle_conversion(lon2), angle_conversion(lat2)\n",
        "    l = R*np.arccos(np.cos(lat1)*np.cos(lat2)*np.cos(lon1-lon2)+\\\n",
        "                        np.sin(lat1)*np.sin(lat2))*conversion_factor\n",
        "    return l\n",
        "\n",
        "def ThreeD_dist(lat1=0,lon1=0,lat2=0,lon2=0,h1=0,h2=0):\n",
        "    \"\"\"caculate the distance of two points, return meters\n",
        "    the lat lon format is dd, the unit of h is m\"\"\"\n",
        "    R = 6371.004\n",
        "    lon1, lat1 = angle_conversion(lon1), angle_conversion(lat1)\n",
        "    lon2, lat2 = angle_conversion(lon2), angle_conversion(lat2)\n",
        "    l = R*np.arccos(np.cos(lat1)*np.cos(lat2)*np.cos(lon1-lon2)+\\\n",
        "                        np.sin(lat1)*np.sin(lat2))\n",
        "    distance=math.sqrt((1000*l)**2+(h1-h2)**2)\n",
        "    return distance\n",
        "\n",
        "def find_header_rows(path_name):\n",
        "    \"\"\"the lens of header\"\"\"\n",
        "    original_file=pd.read_csv(path_name,nrows=12,names=['0','1','2','3','4','5'])\n",
        "    for i in range(len(original_file['0'])):\n",
        "        if original_file['0'][i]=='HEADING':\n",
        "            header_rows=i\n",
        "            break \n",
        "    return header_rows\n",
        "\n",
        "def find_nd(target,lat,lon,lats,lons):\n",
        "    \n",
        "    \"\"\" Bisection method:find the index of nearest distance\"\"\"\n",
        "    row=0\n",
        "    maxrow=len(lats)-1\n",
        "    col=len(lats[0])-1\n",
        "    while col>=0 and row<=maxrow:\n",
        "        distance=dist(lat1=lats[row][col],lat2=lat,lon1=lons[row][col],lon2=lon)\n",
        "        if distance<=target:\n",
        "            break\n",
        "        elif abs(lats[row][col]-lat)<abs(lons[row][col]-lon):\n",
        "            col-=1\n",
        "        else:\n",
        "            row+=1\n",
        "    distance=dist(lat1=lats[row][col],lat2=lat,lon1=lons[row][col],lon2=lon)\n",
        "    row_md,col_md=row,col  #row_md the row of minimum distance\n",
        "    #avoid row,col out of range in next step\n",
        "    if row<3:\n",
        "        row=3\n",
        "    if col<3:\n",
        "        col=3\n",
        "    if row>maxrow-3:\n",
        "        row=maxrow-3\n",
        "    if col>len(lats[0])-4:\n",
        "        col=len(lats[0])-4\n",
        "    for i in range(row-3,row+3,1):\n",
        "        for j in range(col-3,col+3,1):\n",
        "            distance_c=dist(lat1=lats[i][j],lat2=lat,lon1=lons[i][j],lon2=lon)\n",
        "            if distance_c<=distance:\n",
        "                distance=distance_c\n",
        "                row_md,col_md=i,j\n",
        "    return row_md,col_md\n",
        "\n",
        "\n",
        "\n",
        "def fitting(point,lat,lon):\n",
        "    \"\"\"\n",
        "    point represent many data include lat lon and z\n",
        "    format:[[lat,lon,z],[lat1,lon1,z]...]\n",
        "    \"\"\"\n",
        "#represent the value of matrix\n",
        "    ISum = 0.0\n",
        "    X1Sum = 0.0\n",
        "    X2Sum = 0.0\n",
        "    X1_2Sum = 0.0\n",
        "    X1X2Sum = 0.0\n",
        "    X2_2Sum = 0.0\n",
        "    YSum = 0.0\n",
        "    X1YSum = 0.0\n",
        "    X2YSum = 0.0\n",
        "\n",
        "    for i in range(0,len(point)):\n",
        "        \n",
        "        x1i=point[i][0]\n",
        "        x2i=point[i][1]\n",
        "        yi=point[i][2]\n",
        "\n",
        "        ISum = ISum+1\n",
        "        X1Sum = X1Sum+x1i\n",
        "        X2Sum = X2Sum+x2i\n",
        "        X1_2Sum = X1_2Sum+x1i**2\n",
        "        X1X2Sum = X1X2Sum+x1i*x2i\n",
        "        X2_2Sum = X2_2Sum+x2i**2\n",
        "        YSum = YSum+yi\n",
        "        X1YSum = X1YSum+x1i*yi\n",
        "        X2YSum = X2YSum+x2i*yi\n",
        "\n",
        "#  matrix operations\n",
        "# _mat1 is the mat1 inverse matrix\n",
        "    m1=[[ISum,X1Sum,X2Sum],[X1Sum,X1_2Sum,X1X2Sum],[X2Sum,X1X2Sum,X2_2Sum]]\n",
        "    mat1 = np.matrix(m1)\n",
        "    m2=[[YSum],[X1YSum],[X2YSum]]\n",
        "    mat2 = np.matrix(m2)\n",
        "    _mat1 =mat1.getI()\n",
        "    mat3 = _mat1*mat2\n",
        "\n",
        "# use list to get the matrix data\n",
        "    m3=mat3.tolist()\n",
        "    a0 = m3[0][0]\n",
        "    a1 = m3[1][0]\n",
        "    a2 = m3[2][0]\n",
        "    y = a0+a1*lat+a2*lon\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "def fuzzyfinder(user_input, collection):\n",
        "    suggestions = []\n",
        "    pattern = '.*?'.join(user_input)    # Converts 'djm' to 'd.*?j.*?m'\n",
        "    regex = re.compile(pattern)         # Compiles a regex.\n",
        "    for item in collection:\n",
        "        match = regex.search(item)      # Checks if the current item matches the regex.\n",
        "        if match:\n",
        "            suggestions.append((len(match.group()), match.start(), item))\n",
        "    return [x for _, _, x in sorted(suggestions)] \n",
        "\n",
        "def get_doppio_url(date):\n",
        "    url='http://tds.marine.rutgers.edu/thredds/dodsC/roms/doppio/2017_da/his/runs/History_RUN_2018-11-12T00:00:00Z'\n",
        "    return url.replace('2018-11-12',date)\n",
        "\n",
        "\n",
        "def gmt_to_eastern(times_gmt):\n",
        "    \"\"\"GMT time converted to US Eastern Time\"\"\"\n",
        "    eastern = pytz.timezone('US/Eastern')\n",
        "    gmt = pytz.timezone('Etc/GMT')\n",
        "    date = datetime.datetime.strptime(str(times_gmt),'%Y-%m-%d %H:%M:%S')\n",
        "    date_gmt=gmt.localize(date)\n",
        "    easterndate=date_gmt.astimezone(eastern)\n",
        "    return easterndate\n",
        "\n",
        "\n",
        "def  isConnected(address=\"http://server.arcgisonline.com/ArcGIS\"):\n",
        "    \n",
        "    \"check the internet\"\n",
        "    try:\n",
        "        html = requests.get(address,timeout=2)\n",
        "    except:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def keep_number(value,integer_num,decimal_digits):\n",
        "    \"\"\"keep the lens of value\"\"\"    \n",
        "    #ouput data type is str\n",
        "    data=str(value)\n",
        "    if len(data.split('.'))==2:\n",
        "        integer=data.split('.')[0]\n",
        "        decimal=data.split('.')[1]\n",
        "    else:\n",
        "        integer=data\n",
        "        decimal=[]\n",
        "    if integer_num==all:\n",
        "        integer=integer\n",
        "    elif len(integer)>integer_num:\n",
        "        integer=integer[len(integer)-integer_num:]\n",
        "    elif len(integer)<integer_num:\n",
        "        for i in range(integer_num-len(integer)):\n",
        "            integer='0'+integer[:]\n",
        "    if decimal_digits==all:\n",
        "        decimal=decimal\n",
        "    elif len(decimal)>decimal_digits:\n",
        "        decimal=decimal[:decimal_digits]\n",
        "    elif len(decimal)<decimal_digits:\n",
        "        if decimal==[]:\n",
        "            decimal='0'\n",
        "            for i in range(decimal_digits-len(decimal)):\n",
        "                decimal=decimal[:]+'0'\n",
        "        else:\n",
        "            for i in range(decimal_digits-len(decimal)):\n",
        "                decimal=decimal[:]+'0'\n",
        "    return str(integer+'.'+decimal)\n",
        "       \n",
        "\n",
        "def list_all_files(rootdir):\n",
        "    \"\"\"get all files' path and name in rootdirectory\"\"\"\n",
        "    _files = []\n",
        "    list = os.listdir(rootdir) #列出文件夹下所有的目录与文件\n",
        "    for i in range(0,len(list)):\n",
        "           path = os.path.join(rootdir,list[i])\n",
        "           if os.path.isdir(path):\n",
        "              _files.extend(list_all_files(path))\n",
        "           if os.path.isfile(path):\n",
        "              _files.append(path)\n",
        "    return _files\n",
        "\n",
        "\n",
        "def list_sd2uv(s,d):\n",
        "    \"\"\"aim at the list transform the speed and direction data to the x,y components of the arrow vectors(u,v)\"\"\"\n",
        "    u,v=np.zeros(len(s)),np.zeros(len(s))\n",
        "    for i in range(len(s)):\n",
        "        u[i],v[i]=sd2uv(s[i],d[i])\n",
        "    return u,v\n",
        "        \n",
        "    \n",
        "    \n",
        "def list_uv2sd(u,v):\n",
        "    \"\"\"aim at the list transform the x,y components of the arrow vectors(u,v) to the speed and direction data\"\"\"\n",
        "    s,d=np.zeros(len(u)),np.zeros(len(u))\n",
        "    for i in range(len(u)):\n",
        "        s[i],d[i]=uv2sd(u[i],v[i])\n",
        "    return s,d\n",
        "\n",
        "def local2utc(local_st):\n",
        "    \"\"\"\n",
        "    the format of time is datetime: eg.:datetime.datetime(2019, 3, 7, 15, 50, 50)\n",
        "    local time to utc time\"\"\"\n",
        "    time_struct = time.mktime(local_st.timetuple())\n",
        "    utc_st = datetime.datetime.utcfromtimestamp(time_struct)\n",
        "    return utc_st\n",
        "\n",
        "\n",
        "def nrows_len_to(fle,long,name,**kwargs):\n",
        "    df=pd.read_csv(fle,names=['key','value1','value2','value3','value4','value5'])\n",
        "    for i in range(len(df)):\n",
        "        if len(df.iloc[i].dropna())!=long:\n",
        "            break\n",
        "    df=df[:i].dropna(axis=1)\n",
        "    df.columns=name\n",
        "    return df\n",
        "\n",
        "\n",
        "def nrows_to(fle,line,name,**kwargs):\n",
        "    \"\"\"only read the header\"\"\"\n",
        "    df=pd.read_csv(fle,names=['1','2','3','4','5','6'])\n",
        "    for i in range(len(df['1'])):\n",
        "        if df['1'][i]==line:\n",
        "            break\n",
        "    df=df[:i].dropna(axis=1)\n",
        "    df.columns=name\n",
        "    return df\n",
        "\n",
        "    \n",
        "def sd_list_mean(speeds,directions):\n",
        "    \"\"\"aim at the list about average of speed and direction\"\"\"\n",
        "    u_total,v_total=0,0\n",
        "    for a in range(len(speeds)):\n",
        "        u,v=sd2uv(speeds[a],directions[a])\n",
        "        u_total=u_total+u\n",
        "        v_total=v_total+v\n",
        "    u_mean=u_total/len(speeds)\n",
        "    v_mean=v_total/len(speeds)\n",
        "    WS,WD=uv2sd(u_mean,v_mean)\n",
        "    return WS,WD\n",
        "\n",
        "\n",
        "     \n",
        "def sd2uv(s,d):\n",
        "    \"\"\"transform the speed and direction data to the x,y components of the arrow vectors(u,v)\"\"\" \n",
        "    u_t=math.sin(math.radians(d))\n",
        "    v_t=math.cos(math.radians(d))\n",
        "    if abs(u_t)==1:\n",
        "        v=0\n",
        "        u=float(s)*u_t\n",
        "    elif abs(v_t)==1:\n",
        "        u=0\n",
        "        v=float(s)*v_t\n",
        "    else:\n",
        "        u=float(s)*u_t\n",
        "        v=float(s)*v_t\n",
        "    return u,v\n",
        "\n",
        "def skip_len_to(fle,long,**kwargs):\n",
        "    df=pd.read_csv(fle,names=['key','value1','value2','value3','value4','value5'])\n",
        "    for i in range(len(df)):\n",
        "        if len(df.iloc[i].dropna())!=long:\n",
        "            break\n",
        "    return pd.read_csv(fle,skiprows=i)\n",
        "\n",
        "\n",
        "def skip_to(fle, line,**kwargs):\n",
        "    \"\"\"only read the data,not read the header\"\"\"\n",
        "    if os.stat(fle).st_size <= 5:\n",
        "        raise ValueError(\"File is empty\")\n",
        "    with open(fle) as f:\n",
        "        pos = 0\n",
        "        cur_line = f.readline()\n",
        "        while not cur_line.startswith(line):\n",
        "            pos = f.tell()\n",
        "            cur_line = f.readline()\n",
        "        f.seek(pos)\n",
        "        return pd.read_csv(f, **kwargs)\n",
        "\n",
        "\n",
        "def str_similarity_ratio(str1,str2):\n",
        "    \"\"\"caculate the rato of similarity in two string \"\"\"\n",
        "    return difflib.SequenceMatcher(None, str1, str2).quick_ratio()\n",
        "\n",
        "def transform_date(date):\n",
        "    \"\"\"format the time to 10/26/2018\"\"\"\n",
        "    date=date.replace(' ','')\n",
        "    if len(date.split('/'))!=3:\n",
        "        date=date.split('/')[0]+'/'+'01'+'/'+date.split('/')[1]\n",
        "    if len(date.split('/')[0])==1:\n",
        "        date='0'+date.split('/')[0]+'/'+date.split('/')[1]+'/'+date.split('/')[2]\n",
        "    if len(date.split('/')[1])==1:\n",
        "        date=date.split('/')[0]+'/'+'0'+date.split('/')[1]+'/'+date.split('/')[2]\n",
        "    if len(date.split('/')[2])==2:\n",
        "        date=date.split('/')[0]+'/'+date.split('/')[1]+'/'+'20'+date.split('/')[2]\n",
        "    date_data=date.split('/')[2]+date.split('/')[0]+date.split('/')[1]\n",
        "    return date_data\n",
        "\n",
        "def utc2local(utc_st):\n",
        "    \"\"\"\n",
        "    utc_st: the format like this: datetime.datetime(2019, 3, 7, 10, 50, 50)\n",
        "    UTC time to local time\n",
        "    \"\"\"\n",
        "    now_stamp = time.time()\n",
        "    local_time = datetime.datetime.fromtimestamp(now_stamp)\n",
        "    utc_time = datetime.datetime.utcfromtimestamp(now_stamp)\n",
        "    offset = local_time - utc_time\n",
        "    local_st = utc_st + offset\n",
        "    return local_st\n",
        "\n",
        "def uv2sd(u,v):\n",
        "    \"\"\"transform the x,y components of the arrow vectors(u,v) to the speed and direction data\"\"\"\n",
        "#    s=math.sqrt(u**2+v**2)\n",
        "    s=math.sqrt(np.square(u)+np.square(v))\n",
        "    if s==0:\n",
        "        d=0\n",
        "    else:\n",
        "        if abs(v/s)==1:\n",
        "            d=180/np.pi*math.acos(float(v/s))\n",
        "        elif abs(u/s)==1:\n",
        "            d=180/np.pi*math.asin(float(u/s))\n",
        "        else:\n",
        "            dt=180/np.pi*math.atan(float(u/v))\n",
        "            if u>0 and v>0:\n",
        "                d=dt\n",
        "            elif v<0:\n",
        "                d=180+dt\n",
        "            else:\n",
        "                d=360+dt\n",
        "    return s,d\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "580na1Z3e10t",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title gomofs\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Feb 25 15:37:42 2019\n",
        "gets the output from Gulf of Maine Ocean Forecast System with function get_gomofs\n",
        "@author: Lei Zhao with some help from Vitalli and JiM\n",
        "Requires his \"zlconversions\" module in this same directory\n",
        "\n",
        "Modification: March 15, 2019 - added a function(get_gomofs_url_forcast(date,forecastdate=1))\n",
        "Modification: Feb 28, 2020 - made a much simpler function \"get_gomofs\" to get bottom temp and renamed Lei Zhao's as \"get_gomofs_zl\" \n",
        "Note: We might come back to Lei Zhao fancier way to fit the data but here we use the nearest node.\n",
        "\"\"\"\n",
        "import netCDF4\n",
        "import datetime\n",
        "#import zlconversions as zl\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def get_gomofs_url(date):\n",
        "    \"\"\"\n",
        "    input: \"date\" as datetime.datetime(2019, 2, 27, 11, 56, 51)\n",
        "    output: a url for gomofs output\n",
        "    \"\"\"\n",
        "    hours=date.hour\n",
        "    date_str=date.strftime('%Y%m%d%H%M%S')\n",
        "    tn=int(math.floor((hours)/6.0)*6)\n",
        "    tstr='t'+str(tn).zfill(2)+'z'  ## for example: t12z the number is 12\n",
        "    #if round((hours)/3.0-1.5,0)==tn/3:\n",
        "    if tn>=6: \n",
        "        nstr='n006'       # nstr in url represent nowcast string: n003 or n006\n",
        "    else:\n",
        "        nstr='n003'\n",
        "    url='http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/NOAA/GOMOFS/MODELS/'\\\n",
        "    +date_str[:6]+'/nos.gomofs.fields.'+nstr+'.'+date_str[:8]+'.'+tstr+'.nc'\n",
        "    return url\n",
        "\n",
        "def get_gomofs_url_forecast(date,forecastdate=True):\n",
        "    \"\"\"\n",
        "    same as get_gomofs_url but gets the forecast file instead of the nowcast\n",
        "    where \"date\" is a datatime like datetime.datetime(2019, 2, 27, 11, 56, 51, 666857)\n",
        "    forecastdate like date or True\n",
        "    return the url of data\n",
        "    \"\"\"\n",
        "    if forecastdate==True:  #if forcastdate is True: default the forcast date equal to the time of choose file.\n",
        "        forecastdate=date\n",
        "    date=date-datetime.timedelta(hours=1.5)  #the parameter of calculate txx(eg:t00,t06 and so on)\n",
        "    tn=int(math.floor(date.hour/6.0)*6)  #the numer of hours in time index: eg: t12, the number is 12\n",
        "    ymdh=date.strftime('%Y%m%d%H%M%S')[:10]  #for example:2019011112(YYYYmmddHH)\n",
        "    tstr='t'+str(tn).zfill(2)+'z'  #tstr: for example: t12\n",
        "    fstr='f'+str(3+3*math.floor((forecastdate-datetime.timedelta(hours=1.5+tn)-datetime.datetime.strptime(ymdh[:8],'%Y%m%d')).seconds/3600./3.)).zfill(3)#fnstr:the number in forcast index, for example f006 the number is 6\n",
        "    url='http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/NOAA/GOMOFS/MODELS/'\\\n",
        "    +ymdh[:6]+'/nos.gomofs.fields.'+fstr+'.'+ymdh[:8]+'.'+tstr+'.nc'\n",
        "    return url\n",
        "def get_gomofs(date_time,lat,lon,mindistance=20):# JiM's simple version for bottom temp\n",
        "    \"\"\"\n",
        "    JiM's simplified version of Lei Zhao's function gets only bottom temp\n",
        "    the format time(GMT) is: datetime.datetime(2019, 2, 27, 11, 56, 51, 666857)\n",
        "    lat and lon use decimal degrees where lon is negative number\n",
        "    returns the BOTTOM temperature (degC) of specify location\n",
        "    HARDCODED TO RETURN BOTTOM TEMP\n",
        "    \"\"\"\n",
        "    rho_index=0 # for bottom layer\n",
        "    if not gomofs_coordinaterange(lat,lon):\n",
        "        print('lat and lon out of range in gomofs')\n",
        "        return np.nan\n",
        "    if date_time<datetime.datetime.strptime('2018-07-01 00:00:00','%Y-%m-%d %H:%M:%S'):\n",
        "        print('Time out of range, time start :2018-07-01 00:00:00z')\n",
        "        return np.nan\n",
        "    if date_time>datetime.datetime.utcnow()+datetime.timedelta(days=3): #forecast time under 3 days\n",
        "        print('beyond the forecast time of 3 days')\n",
        "        return np.nan\n",
        "    if date_time>datetime.datetime.utcnow():\n",
        "        url=get_gomofs_url_forecast(datetime.datetime.utcnow(),date_time)\n",
        "    else:\n",
        "        url=get_gomofs_url(date_time)\n",
        "    #start download data\n",
        "    nc=netCDF4.Dataset(str(url))\n",
        "    gomofs_lons=nc.variables['lon_rho'][:]\n",
        "    gomofs_lats=nc.variables['lat_rho'][:]\n",
        "    gomofs_temp=nc.variables['temp']\n",
        "    #caculate the index of the nearest four points using a \"find_nd\" function in Lei Zhao's conversion module   \n",
        "    target_distance=2*dist(lat1=gomofs_lats[0][0],lon1=gomofs_lons[0][0],lat2=gomofs_lats[0][1],lon2=gomofs_lons[0][1])\n",
        "    eta_rho,xi_rho=find_nd(target=target_distance,lat=lat,lon=lon,lats=gomofs_lats,lons=gomofs_lons)\n",
        "    if dist(lat1=lat,lon1=lon,lat2=gomofs_lats[eta_rho][xi_rho],lon2=gomofs_lons[eta_rho][xi_rho])>mindistance:\n",
        "        print('THE location is out of range')\n",
        "        return np.nan\n",
        "    temperature=gomofs_temp[0][rho_index][eta_rho][xi_rho]\n",
        "    return temperature\n",
        "\n",
        "\n",
        "def gomofs_coordinaterange(lat,lon):\n",
        "    f1=-0.7490553378867058*lat-lon-40.98355685763821<=0\n",
        "    f2=-0.5967392371008197*lat-lon-36.300860518805024>=0\n",
        "    f3=2.695505391925802*lat-lon-188.76889647321198<=0\n",
        "    f4=2.689125428655328*lat-lon-173.5017523298927>=0\n",
        "    if f1 and f2 and f3 and f4:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-c9wr-We7nN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title doppio { form-width: \"5%\" }\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Nov 21 09:10:47 2018\n",
        "@author: Lei Zhao with help from JiM and Vitalii\n",
        "\n",
        "Modifications by Lei Zhao Feb 27 2019\n",
        "-updates the method of calculate the layer_index in function of get doppio\n",
        "-updated the method of calculate the min,second small and third small distance and index\n",
        "\n",
        "Modifications by lei Zhao Mar 20, 2019\n",
        "-updated the way to get temperature quicker\n",
        "\n",
        "Modifications by JiM Mar 21, 2019\n",
        "-just added some more documentation and spelling changes\n",
        "\"\"\"\n",
        "#!pip install netCDF4\n",
        "import netCDF4\n",
        "import datetime\n",
        "#import zlconversions as zl  # this is a set of Lei Zhao's functions that must be in same folder \n",
        "import numpy as np\n",
        "def get_doppio_url(date):\n",
        "    url='http://tds.marine.rutgers.edu/thredds/dodsC/roms/doppio/2017_da/his/runs/History_RUN_2018-11-12T00:00:00Z'\n",
        "    return url.replace('2018-11-12',date)\n",
        "def get_doppio(time='2018-11-12 12:00:00',lat=0,lon=0,depth='bottom',fortype='temperature'):\n",
        "    \"\"\"\n",
        "    notice:\n",
        "        the format of time is like \"%Y-%m-%d %H:%M:%S\" this time is utctime  or it can also be datetime\n",
        "        the depth is under the bottom depth\n",
        "    the module only output the temperature of point location\n",
        "    if fortype ='temperature',only return temperature, else return temperature and depth\n",
        "    \"\"\"\n",
        "    #if depth==99999:\n",
        "    #   depth='bottom'\n",
        "    if not doppio_coordinate(lat,lon):\n",
        "        print('the lat and lon out of range in doppio')\n",
        "        return np.nan,np.nan\n",
        "    if type(time)==str:\n",
        "        date_time=datetime.datetime.strptime(time,'%Y-%m-%d %H:%M:%S') # transform time format\n",
        "    elif type(time)==datetime.datetime:\n",
        "        date_time=time\n",
        "    else:\n",
        "        print('check the type of input time in get_doppio')\n",
        "    for m in range(0,7):\n",
        "        try:\n",
        "            url_time=(date_time-datetime.timedelta(days=m)).strftime('%Y-%m-%d')#\n",
        "            url=get_doppio_url(url_time)\n",
        "            #get the data \n",
        "            nc=netCDF4.Dataset(url)\n",
        "            lons=nc.variables['lon_rho'][:]\n",
        "            lats=nc.variables['lat_rho'][:]\n",
        "            doppio_time=nc.variables['time']\n",
        "            doppio_rho=nc.variables['s_rho']\n",
        "            doppio_temp=nc.variables['temp']\n",
        "            doppio_h=nc.variables['h']\n",
        "        except:\n",
        "            continue\n",
        "        min_diff_time=abs(datetime.datetime(2017,11,1,0,0,0)+datetime.timedelta(hours=int(doppio_time[0]))-date_time)\n",
        "        min_diff_index=0\n",
        "        for i in range(1,len(doppio_time)):\n",
        "            diff_time=abs(datetime.datetime(2017,11,1,0,0,0)+datetime.timedelta(hours=int(doppio_time[i]))-date_time)\n",
        "            if diff_time<min_diff_time:\n",
        "                min_diff_time=diff_time\n",
        "                min_diff_index=i\n",
        "        #calculate the min,second small and third small distance and index\n",
        "        target_distance=dist(lat1=lats[0][0],lon1=lons[0][0],lat2=lats[0][1],lon2=lons[0][1])\n",
        "        index_1,index_2=find_nd(target=target_distance,lat=lat,lon=lon,lats=lats,lons=lons)\n",
        "\n",
        "        #calculate the optimal layer index added this section Feb 2020\n",
        "        doppio_depth=nc['h'][index_1][index_2]\n",
        "        if depth > doppio_depth:# case of bottom\n",
        "            S_coordinate=1\n",
        "        else:\n",
        "            S_coordinate=float(depth)/float(doppio_depth)\n",
        "        if 0<=S_coordinate<1:\n",
        "            layer_index=39-int(S_coordinate/0.025)#doppio_temp=temp[itime,39-int(S_coordinate/0.025),index_1,index_2]# because there are 0.025 between each later\n",
        "        elif S_coordinate==1:\n",
        "            layer_index=0#doppio_temp=temp[itime][0][index_1][index_2]\n",
        "        else:\n",
        "            layer_index=0#doppio_temp=temp[itime][0][index_1][index_2]\n",
        "        #return doppio_temp\n",
        "        #layer_index=0  #specify the initial layer index\n",
        "        '''if depth!='bottom':\n",
        "            h_distance=depth+doppio_rho[0]*doppio_h[index_1,index_2]  #specify the initial distanc of high\n",
        "            for i in range(len(doppio_rho)):\n",
        "                if abs(depth+doppio_rho[0]*doppio_h[index_1,index_2])<=h_distance:\n",
        "                    h_distance=depth+doppio_rho[i]*doppio_h[index_1,index_2]\n",
        "                    layer_index=i\n",
        "                if depth>doppio_h[index_1,index_2]:\n",
        "                    print (\"the depth is out of the depth of bottom:\"+str(doppio_h[index_1,index_2]))\n",
        "        '''\n",
        "        if index_1==0:\n",
        "            index_1=1\n",
        "        if index_1==len(lats)-1:\n",
        "            index_1=len(lats)-2\n",
        "        if index_2==0:\n",
        "            index_2=1\n",
        "        if index_2==len(lats[0])-1:\n",
        "            index_2=len(lats[0])-2\n",
        "        while True:\n",
        "            point=[[lats[index_1][index_2],lons[index_1][index_2],doppio_temp[min_diff_index,layer_index,index_1,index_2]],\\\n",
        "            [lats[index_1-1][index_2],lons[index_1-1][index_2],doppio_temp[min_diff_index,layer_index,(index_1-1),index_2]],\\\n",
        "            [lats[index_1+1][index_2],lons[index_1+1][index_2],doppio_temp[min_diff_index,layer_index,(index_1+1),index_2]],\\\n",
        "            [lats[index_1][index_2-1],lons[index_1][index_2-1],doppio_temp[min_diff_index,layer_index,index_1,(index_2-1)]],\\\n",
        "            [lats[index_1][index_2+1],lons[index_1][index_2+1],doppio_temp[min_diff_index,layer_index,index_1,(index_2+1)]]]\n",
        "            break\n",
        "        point_temp=fitting(point,lat,lon)\n",
        "        if np.isnan(point_temp):\n",
        "            continue\n",
        "        if min_diff_time<datetime.timedelta(hours=1):\n",
        "            break\n",
        "    if fortype=='temperature':\n",
        "        return point_temp\n",
        "    else:\n",
        "        return point_temp,doppio_h[index_1,index_2]\n",
        "\n",
        "def fitting(point,lat,lon):\n",
        "#represent the value of matrix\n",
        "    ISum = 0.0\n",
        "    X1Sum = 0.0\n",
        "    X2Sum = 0.0\n",
        "    X1_2Sum = 0.0\n",
        "    X1X2Sum = 0.0\n",
        "    X2_2Sum = 0.0\n",
        "    YSum = 0.0\n",
        "    X1YSum = 0.0\n",
        "    X2YSum = 0.0\n",
        "\n",
        "    for i in range(0,len(point)):\n",
        "        \n",
        "        x1i=point[i][0]\n",
        "        x2i=point[i][1]\n",
        "        yi=point[i][2]\n",
        "\n",
        "        ISum = ISum+1\n",
        "        X1Sum = X1Sum+x1i\n",
        "        X2Sum = X2Sum+x2i\n",
        "        X1_2Sum = X1_2Sum+x1i**2\n",
        "        X1X2Sum = X1X2Sum+x1i*x2i\n",
        "        X2_2Sum = X2_2Sum+x2i**2\n",
        "        YSum = YSum+yi\n",
        "        X1YSum = X1YSum+x1i*yi\n",
        "        X2YSum = X2YSum+x2i*yi\n",
        "\n",
        "#  matrix operations\n",
        "# _mat1 is the mat1 inverse matrix\n",
        "    m1=[[ISum,X1Sum,X2Sum],[X1Sum,X1_2Sum,X1X2Sum],[X2Sum,X1X2Sum,X2_2Sum]]\n",
        "    mat1 = np.matrix(m1)\n",
        "    m2=[[YSum],[X1YSum],[X2YSum]]\n",
        "    mat2 = np.matrix(m2)\n",
        "    _mat1 =mat1.getI()\n",
        "    mat3 = _mat1*mat2\n",
        "\n",
        "# use list to get the matrix data\n",
        "    m3=mat3.tolist()\n",
        "    a0 = m3[0][0]\n",
        "    a1 = m3[1][0]\n",
        "    a2 = m3[2][0]\n",
        "    y = a0+a1*lat+a2*lon\n",
        "\n",
        "    return y\n",
        "\n",
        "def doppio_coordinate(lat,lon):\n",
        "    f1=-0.8777722604596849*lat-lon-23.507489034447012>=0\n",
        "    f2=-1.072648270137022*lat-40.60872567829448-lon<=0\n",
        "    f3=1.752828434063416*lat-131.70051451008493-lon>=0\n",
        "    f4=1.6986954871237598*lat-lon-144.67649951783605<=0\n",
        "    if f1 and f2 and f3 and f4:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6glKAZdsfJED",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title fvcom\n",
        "\n",
        "# routines to extract FVCOM\n",
        "# written by several interns \n",
        "# cleaned up by JiM in May 2020\n",
        "\n",
        "from datetime import datetime as dt\n",
        "from datetime import timedelta as td\n",
        "import numpy as np\n",
        "import netCDF4\n",
        "\n",
        "def nearlonlat(lon,lat,lonp,latp): # needed for the next function get_FVCOM_bottom_temp\n",
        "    \"\"\"\n",
        "    i=nearlonlat(lon,lat,lonp,latp) change\n",
        "    find the closest node in the array (lon,lat) to a point (lonp,latp)\n",
        "    input:\n",
        "        lon,lat - np.arrays of the grid nodes, spherical coordinates, degrees\n",
        "        lonp,latp - point on a sphere\n",
        "        output:\n",
        "            i - index of the closest node\n",
        "            For coordinates on a plane use function nearxy           \n",
        "            Vitalii Sheremet, FATE Project  \n",
        "    \"\"\"\n",
        "    cp=np.cos(latp*np.pi/180.)\n",
        "    # approximation for small distance\n",
        "    dx=(lon-lonp)*cp\n",
        "    dy=lat-latp\n",
        "    dist2=dx*dx+dy*dy\n",
        "    i=np.argmin(dist2)\n",
        "    return i\n",
        "\n",
        "def get_FVCOM_url(dtime):\n",
        "    # \"dtime\" is in the form of datetime\n",
        "    # get fvcom url based on time wanted\n",
        "    if (dtime-dt.now())>td(days=-2): # forecast field\n",
        "        url='http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc' \n",
        "    elif (dtime>=dt(2016,7,1)) and (dtime<dt(2020,3,1)):\n",
        "        url='http://www.smast.umassd.edu:8080/thredds/dodsC/models/fvcom/NECOFS/Archive/NECOFS_GOM/2019/gom4_201907.nc'\n",
        "        url=url.replace('201907',dtime.strftime('%Y%m'))\n",
        "        url=url.replace('2019',dtime.strftime('%Y'))\n",
        "    elif dtime<=dt(2016,1,1): # 30 year hindcast\n",
        "        url = 'http://www.smast.umassd.edu:8080/thredds/dodsC/fvcom/hindcasts/30yr_gom3'\n",
        "    else:\n",
        "        url=np.nan # not available\n",
        "    return url\n",
        "\n",
        "def get_FVCOM_temp(dtime,lati,loni,depth): # gets modeled temp using GOM3 forecast\n",
        "        '''\n",
        "        Taken primarily from Rich's blog at: http://rsignell-usgs.github.io/blog/blog/2014/01/08/fvcom/ on July 30, 2018\n",
        "        where lati and loni are the position of interest, dtime is the datetime, and depth is \"99999\" for bottom\n",
        "        '''\n",
        "        urlfvcom=get_FVCOM_url(dtime)\n",
        "        nc = netCDF4.Dataset(urlfvcom).variables\n",
        "        #first find the index of the grid \n",
        "        lat = nc['lat'][:]\n",
        "        lon = nc['lon'][:]\n",
        "        inode = nearlonlat(lon,lat,loni,lati)\n",
        "        #second find the index of time\n",
        "        time_var = nc['time']\n",
        "        itime = netCDF4.date2index(dtime,time_var,select='nearest')# where startime in datetime\n",
        "        # figure out layer from depth\n",
        "        w_depth=nc['h'][inode]\n",
        "        if depth==99999: # for bottom\n",
        "            layer=-1\n",
        "        else:\n",
        "            layer=int(round(depth/w_depth*45.))\n",
        "        return nc['temp'][itime,layer,inode].data.flatten()[0] # had to add this suffix to extract value from a masked array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTmrKTqhadsE",
        "colab_type": "code",
        "outputId": "7f12d5cb-c017-4398-c315-18ea7f8f192b",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#@title get_models_cell { form-width: \"10%\" }\n",
        "#!pip install netCDF4\n",
        "'''\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/colab/')\n",
        "import gomofs_modules\n",
        "import doppio_modules\n",
        "import fvcom_modules\n",
        "'''\n",
        "from datetime import datetime as dt\n",
        "\n",
        "#HARDCODES ############\n",
        "# Gets imput from terminal\n",
        "lat=41.9\n",
        "lon=-70.25\n",
        "depth=99999#99999 for bottom\n",
        "datet=dt(2019,8,15,0,0,0) #GMT time\n",
        "clim='no' # set to yes if you have climatology files handy\n",
        "clim_files_directory='/net/data5/jmanning/clim/'\n",
        "#####################\n",
        "\n",
        "\n",
        "# get DOPPIO\n",
        "try:\n",
        "  tdo=get_doppio(datet,lat,lon,depth,'temperature')\n",
        "  print('doppio = ','%.3f' % tdo)\n",
        "except:\n",
        "  print('doppio not available?')\n",
        "\n",
        "# get FVCOM\n",
        "try:\n",
        "    #url=fvcom_modules.get_FVCOM_url(datet)\n",
        "    tf=get_FVCOM_temp(datet,lat,lon,depth)# \n",
        "    print('fvcom =','%.3f' % tf)\n",
        "except:\n",
        "    print('fvcom not available?')\n",
        "\n",
        "# get GOMOFS bottom temp\n",
        "try:\n",
        "    tg=get_gomofs(datet,lat,lon,mindistance=20)\n",
        "    print('gomofs = ','%.3f' % tg)\n",
        "except:\n",
        "    print('gomofs not available?')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "doppio =  8.771\n",
            "fvcom = 11.385\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}